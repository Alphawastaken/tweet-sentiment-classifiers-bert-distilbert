{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T19:13:57.584538Z",
     "iopub.status.busy": "2025-06-07T19:13:57.584343Z",
     "iopub.status.idle": "2025-06-07T19:14:27.579953Z",
     "shell.execute_reply": "2025-06-07T19:14:27.579347Z",
     "shell.execute_reply.started": "2025-06-07T19:13:57.584520Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.9/289.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.3/118.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.12.0 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.8.4.1 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.3.3.83 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.9.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.7.3.90 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.8.93 which is incompatible.\n",
      "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.8.93 which is incompatible.\n",
      "bigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-07 19:14:16.397203: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1749323656.589231      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1749323656.644428      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers datasets evaluate contractions\n",
    "\n",
    "import pandas as pd                \n",
    "import numpy as np                 \n",
    "import torch                       \n",
    "import torch.nn as nn              \n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "\n",
    "\n",
    "from transformers import (\n",
    "    DistilBertTokenizer,                   \n",
    "    DistilBertForSequenceClassification,   \n",
    "    get_scheduler,                        \n",
    "    DataCollatorWithPadding,               \n",
    "    DistilBertConfig                       \n",
    ")\n",
    "\n",
    "from torch.optim import AdamW              \n",
    "from sklearn.metrics import accuracy_score, classification_report  \n",
    "from tqdm import tqdm                      \n",
    "import random                              \n",
    "import re                                  \n",
    "import emoji                               \n",
    "import html                                \n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "from contractions import fix as fix_contractions  \n",
    "import torch.nn.functional as F            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 🧪 Setup & Dependencies\n",
    "# Install necessary packages and import required libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:38:47.433416Z",
     "iopub.status.busy": "2025-06-01T14:38:47.432964Z",
     "iopub.status.idle": "2025-06-01T14:38:47.442548Z",
     "shell.execute_reply": "2025-06-01T14:38:47.441457Z",
     "shell.execute_reply.started": "2025-06-01T14:38:47.433394Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Set a random seed for reproducibility\n",
    "SEED = 42\n",
    "\n",
    "#Ensure reproducibility across runs for Python's built-in random module\n",
    "random.seed(SEED)\n",
    "\n",
    "#Set the seed for NumPy random number generator\n",
    "np.random.seed(SEED)\n",
    "\n",
    "#Set the seed for PyTorch CPU and GPU (if available)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "#Ensure deterministic behavior in CUDA operations (if using GPU)\n",
    "#This may slightly reduce performance but guarantees reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# # 🔁 Reproducibility\n",
    "# Set random seeds for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:38:47.444620Z",
     "iopub.status.busy": "2025-06-01T14:38:47.444368Z",
     "iopub.status.idle": "2025-06-01T14:38:48.161820Z",
     "shell.execute_reply": "2025-06-01T14:38:48.161202Z",
     "shell.execute_reply.started": "2025-06-01T14:38:47.444597Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-3-distil-bert/train_dataset.csv\")\n",
    "val_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-3-distil-bert/val_dataset.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-3-distil-bert/test_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 📥 Load Data\n",
    "# Read train, validation, and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:38:48.162695Z",
     "iopub.status.busy": "2025-06-01T14:38:48.162474Z",
     "iopub.status.idle": "2025-06-01T14:39:04.815508Z",
     "shell.execute_reply": "2025-06-01T14:39:04.814946Z",
     "shell.execute_reply.started": "2025-06-01T14:38:48.162678Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Initialize a tweet-specific tokenizer from NLTK:\n",
    "# - preserve_case=False: lowercase all text\n",
    "# - reduce_len=True: shorten repeated characters (e.g., \"soooo\" → \"soo\")\n",
    "# - strip_handles=False: keep Twitter handles (they'll be replaced manually later)\n",
    "tweet_tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True, strip_handles=False)\n",
    "\n",
    "#Define a tweet preprocessing function\n",
    "def preprocess_tweet(text):\n",
    "    #Convert emojis into textual descriptions (e.g., \"😊\" → \" smile \")\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    \n",
    "    #Unescape any HTML entities (e.g., \"&amp;\" → \"&\")\n",
    "    text = html.unescape(text)\n",
    "    \n",
    "    #Replace URLs with a placeholder\n",
    "    text = re.sub(r\"http\\S+|www\\.\\S+\", \"URL\", text)\n",
    "    \n",
    "    #Replace user mentions (e.g., @user123) with a placeholder\n",
    "    text = re.sub(r\"@\\w+\", \"USER\", text)\n",
    "    \n",
    "    #Separate hashtags from the words (e.g., \"#happy\" → \" happy\")\n",
    "    text = re.sub(r\"#(\\w+)\", r\" \\1\", text)\n",
    "    \n",
    "    #Expand contractions (e.g., \"don't\" → \"do not\")\n",
    "    text = fix_contractions(text)\n",
    "    \n",
    "    #Remove space before punctuation marks\n",
    "    text = re.sub(r\"\\s+([?.!,])\", r\"\\1\", text)\n",
    "    \n",
    "    #Replace repeated punctuation (e.g., \"!!!\" → \"!\")\n",
    "    text = re.sub(r\"([?.!,])\\1+\", r\"\\1\", text)\n",
    "    \n",
    "    #Reduce character repetitions (e.g., \"soooo\" → \"soo\")\n",
    "    text = re.sub(r\"(.)\\1{2,}\", r\"\\1\\1\", text)\n",
    "    \n",
    "    #Replace common emoticons with text labels\n",
    "    emoticons = {r\":\\)\": \"smile\", r\":D\": \"laugh\", r\":\\(\": \"sad\", r\":P\": \"playful\", r\";\\)\": \"wink\"}\n",
    "    for emot, token in emoticons.items():\n",
    "        text = re.sub(re.escape(emot), f\" {token} \", text)\n",
    "    \n",
    "    #Remove non-ASCII characters\n",
    "    text = re.sub(r\"[^\\x00-\\x7F]+\", \" \", text)\n",
    "    \n",
    "    #Normalize whitespace and strip leading/trailing spaces\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    \n",
    "    return text\n",
    "\n",
    "#Apply preprocessing to the training and validation datasets\n",
    "train_df[\"CleanText\"] = train_df[\"Text\"].apply(preprocess_tweet)\n",
    "val_df[\"CleanText\"] = val_df[\"Text\"].apply(preprocess_tweet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 🧹 Preprocessing\n",
    "# Define a tweet-specific text cleaning function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:39:04.816477Z",
     "iopub.status.busy": "2025-06-01T14:39:04.816223Z",
     "iopub.status.idle": "2025-06-01T14:39:04.821862Z",
     "shell.execute_reply": "2025-06-01T14:39:04.821118Z",
     "shell.execute_reply.started": "2025-06-01T14:39:04.816450Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Custom PyTorch Dataset class for handling tweet data\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=128):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.labels = labels\n",
    "        \n",
    "        #Preprocess all input texts (tweets)\n",
    "        self.texts = [preprocess_tweet(t) for t in texts]\n",
    "        \n",
    "        #Tokenize the cleaned texts using the provided tokenizer (e.g.,DistilBERT tokenizer)\n",
    "        self.encodings = self.tokenizer(\n",
    "            self.texts,\n",
    "            truncation=True,           #Truncate sequences longer than max_len\n",
    "            padding='max_length',      #Pad sequences to the same max_len\n",
    "            max_length=max_len,        #Maximum sequence length\n",
    "            return_tensors='pt'        #Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Retrieve the tokenized input at index `idx`\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        \n",
    "        #Add the corresponding label (as a tensor) if labels are available\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        \n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        #Return the number of samples in the dataset\n",
    "        return len(self.labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 📦 Dataset Class\n",
    "# Custom dataset that tokenizes the text using DistilBERT tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:39:04.823225Z",
     "iopub.status.busy": "2025-06-01T14:39:04.822640Z",
     "iopub.status.idle": "2025-06-01T14:40:42.656513Z",
     "shell.execute_reply": "2025-06-01T14:40:42.655860Z",
     "shell.execute_reply.started": "2025-06-01T14:39:04.823194Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Load the pretrained DistilBERT tokenizer (lowercased version)\n",
    "#This tokenizer will convert raw text into input IDs and attention masks\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "#Load the pretrained DistilBERT model for sequence classification\n",
    "#num_labels=2 indicates binary classification (e.g.,positive vs.negative sentiment)\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    \"distilbert-base-uncased\",\n",
    "    num_labels=2\n",
    ")\n",
    "\n",
    "#Create the training dataset using the custom TweetDataset class\n",
    "#Converts raw texts and labels into tokenized tensors\n",
    "train_dataset = TweetDataset(\n",
    "    train_df[\"Text\"].tolist(),       #Raw tweets\n",
    "    train_df[\"Label\"].tolist(),      #Corresponding labels\n",
    "    tokenizer                        #Tokenizer instance\n",
    ")\n",
    "\n",
    "#create the validation dataset similarly\n",
    "val_dataset = TweetDataset(\n",
    "    val_df[\"Text\"].tolist(),\n",
    "    val_df[\"Label\"].tolist(),\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "#Create the test dataset\n",
    "#Labels are dummy (e.g.,all zeros) since test labels may be unknown or not used during inference\n",
    "test_dataset = TweetDataset(\n",
    "    test_df[\"Text\"].tolist(),\n",
    "    [0]*len(test_df),                #Placeholder labels\n",
    "    tokenizer\n",
    ")\n",
    "\n",
    "#Create a data collator to dynamically pad inputs in a batch\n",
    "#Ensures that all sequences in a batch are padded to the length of the longest one\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 🤖 Model and Tokenizer\n",
    "# Load the pre-trained DistilBERT model and tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:40:42.657509Z",
     "iopub.status.busy": "2025-06-01T14:40:42.657285Z",
     "iopub.status.idle": "2025-06-01T14:40:42.662277Z",
     "shell.execute_reply": "2025-06-01T14:40:42.661485Z",
     "shell.execute_reply.started": "2025-06-01T14:40:42.657492Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "batch_size = 8 #Best value after optuna\n",
    "learning_rate = 1.4647207744407194e-05#Best value after optuna\n",
    "num_epochs = 2#Best value after optuna\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, collate_fn=data_collator)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=data_collator)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 🛠️ Hyperparameters & Dataloaders\n",
    "# Define training parameters and construct dataloaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:40:42.663309Z",
     "iopub.status.busy": "2025-06-01T14:40:42.663035Z",
     "iopub.status.idle": "2025-06-01T14:40:42.918053Z",
     "shell.execute_reply": "2025-06-01T14:40:42.917251Z",
     "shell.execute_reply.started": "2025-06-01T14:40:42.663286Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, weight_decay=0.01)\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\"cosine_with_restarts\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # ⚙️ Training Setup\n",
    "# Prepare optimizer, learning rate scheduler, and move model to GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-01T14:40:42.920902Z",
     "iopub.status.busy": "2025-06-01T14:40:42.920658Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Initialize tracking variables\n",
    "best_val_acc = 0\n",
    "best_model_state = None\n",
    "train_losses, val_losses, val_accuracies = [], [], []\n",
    "val_probs, val_targets = [], []\n",
    "\n",
    "#Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "\n",
    "    #Validation loop\n",
    "    model.eval()\n",
    "    all_labels, all_preds, all_probs = [], [], []\n",
    "    total_val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            logits = outputs.logits\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            #Get prediction probabilities and labels\n",
    "            probs = F.softmax(logits, dim=1)[:, 1]\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "\n",
    "            all_probs.extend(probs.cpu().numpy())\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    acc = accuracy_score(all_labels, all_preds)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(acc)\n",
    "    val_probs = all_probs\n",
    "    val_targets = all_labels\n",
    "\n",
    "    #Print results for this epoch\n",
    "    print(f\"[DistilBERT] Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, Accuracy = {acc:.4f}\")\n",
    "    print(classification_report(all_labels, all_preds))\n",
    "\n",
    "    #Save the best model state\n",
    "    if acc > best_val_acc:\n",
    "        best_val_acc = acc\n",
    "        best_model_state = model.state_dict()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 🎯 Training Loop\n",
    "# Perform training with validation and checkpointing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def extract_cls_embeddings_distilbert(model, dataloader):\n",
    "    model.eval()\n",
    "    embeddings = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            outputs = model.distilbert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_embeds = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "            embeddings.append(cls_embeds)\n",
    "            if 'labels' in batch:\n",
    "                labels.extend(batch['labels'].cpu().numpy())\n",
    "    embeddings = np.vstack(embeddings)\n",
    "    labels = np.array(labels)\n",
    "    return embeddings, labels\n",
    "\n",
    "distilbert_embeddings, distilbert_labels = extract_cls_embeddings_distilbert(model, val_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 🔍 Extract CLS Embeddings\n",
    "# For visualization tasks like t-SNE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model_state)\n",
    "model.eval()\n",
    "\n",
    "all_preds = []\n",
    "with torch.no_grad():\n",
    "    for batch in test_loader:\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        preds = torch.argmax(outputs.logits, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "test_df[\"Label\"] = all_preds\n",
    "test_df[[\"ID\", \"Label\"]].to_csv(\"submission.csv\", index=False)\n",
    "print(\"✅ DistilBERT submission saved.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # 📝 Save Submission\n",
    "# Generate predictions for the test set and save them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CODE FOR ALL THE GRAPHS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Imports ====================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.metrics import accuracy_score, classification_report, roc_curve, auc, confusion_matrix\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import emoji\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📦 Imports\n",
    "\n",
    "Load essential Python libraries for data handling, visualization, evaluation, and sentiment analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Data Variables ====================\n",
    "y_train = train_df[\"Label\"].values\n",
    "y_val = val_df[\"Label\"].values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧾 Prepare Label Variables\n",
    "\n",
    "Extract target labels for training and validation sets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== t-SNE on DistilBERT ====================\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, n_iter=1000, random_state=42)\n",
    "distilbert_tsne_embeds = tsne.fit_transform(distilbert_embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if l == 0 else 'green' for l in distilbert_labels]\n",
    "plt.scatter(distilbert_tsne_embeds[:, 0], distilbert_tsne_embeds[:, 1], c=colors, alpha=0.6)\n",
    "plt.title(\"t-SNE Visualization of DistilBERT [CLS] Embeddings\")\n",
    "plt.xlabel(\"t-SNE Dim 1\")\n",
    "plt.ylabel(\"t-SNE Dim 2\")\n",
    "plt.legend(handles=[\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='Negative', markerfacecolor='red', markersize=8),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='Positive', markerfacecolor='green', markersize=8)\n",
    "])\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 t-SNE Visualization of DistilBERT Embeddings\n",
    "\n",
    "Visualize high-dimensional DistilBERT `[CLS]` embeddings using t-SNE to explore separability between positive and negative classes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Word Cloud ====================\n",
    "def plot_wordcloud(text_series, title, filename=None):\n",
    "    text = ' '.join(text_series.dropna().astype(str))\n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    if filename:\n",
    "        plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_wordcloud(train_df['Text'], 'Word Cloud (Raw Tweets)', 'raw_wc.png')\n",
    "plot_wordcloud(train_df['CleanText'], 'Word Cloud (Cleaned Tweets)', 'clean_wc.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ☁️ Word Clouds: Raw vs Cleaned Tweets\n",
    "\n",
    "Visualize the most frequent words in raw and preprocessed tweets using word clouds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Length Distribution ====================\n",
    "def plot_length_distribution(raw_texts, clean_texts, filename=None):\n",
    "    raw_lengths = raw_texts.dropna().astype(str).str.split().apply(len)\n",
    "    clean_lengths = clean_texts.dropna().astype(str).str.split().apply(len)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(raw_lengths, bins=50, alpha=0.6, label='Raw', color='red')\n",
    "    plt.hist(clean_lengths, bins=50, alpha=0.6, label='Clean', color='green')\n",
    "    plt.xlabel(\"Text Length (Tokens)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Text Length Distribution: Raw vs Clean\")\n",
    "    plt.legend()\n",
    "    if filename:\n",
    "        plt.savefig(filename)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_length_distribution(train_df['Text'], train_df['CleanText'], 'text_len_dist.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📏 Text Length Distribution\n",
    "\n",
    "Compare token length distributions of raw and cleaned tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Emoji Frequency ====================\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji.EMOJI_DATA]\n",
    "\n",
    "def plot_emoji_freq(texts, top_n=10, filename=None):\n",
    "    all_emojis = []\n",
    "    for text in texts.dropna().astype(str):\n",
    "        all_emojis.extend(extract_emojis(text))\n",
    "\n",
    "    top_emojis = Counter(all_emojis).most_common(top_n)\n",
    "    if not top_emojis:\n",
    "        print(\"No emojis found.\")\n",
    "        return\n",
    "\n",
    "    labels, values = zip(*top_emojis)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(labels, values, color='orange')\n",
    "    plt.title(\"Top Emojis in Raw Tweets\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    if filename:\n",
    "        plt.savefig(filename)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_emoji_freq(train_df['Text'], top_n=10, filename='emoji_freq.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 😊 Top Emoji Frequency\n",
    "\n",
    "Display the top 10 most used emojis in raw tweets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Sentiment Polarity Distribution ====================\n",
    "def plot_sentiment_distribution(texts, filename=None):\n",
    "    texts = texts.dropna().astype(str)\n",
    "    polarities = [TextBlob(text).sentiment.polarity for text in texts]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(polarities, bins=50, color='blue', alpha=0.7)\n",
    "    plt.xlabel(\"Polarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Sentiment Polarity Distribution (TextBlob)\")\n",
    "    if filename:\n",
    "        plt.savefig(filename)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_sentiment_distribution(train_df['Text'], filename='sent_pol_raw.png')\n",
    "plot_sentiment_distribution(train_df['CleanText'], filename='sent_pol_clean.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Sentiment Polarity Distribution\n",
    "\n",
    "Plot sentiment polarity distribution (range -1 to 1) using TextBlob for both raw and cleaned text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== ROC Curve ====================\n",
    "fpr, tpr, _ = roc_curve(val_targets, val_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\", color='darkorange')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Validation ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🧪 ROC Curve on Validation Set\n",
    "\n",
    "Plot the ROC curve and calculate AUC for binary classification performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Training Curve ====================\n",
    "plt.figure()\n",
    "plt.plot(train_losses, label='Train Loss', color='blue')\n",
    "plt.plot(val_losses, label='Validation Loss', color='green')\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📉 Training & Validation Loss Curve\n",
    "\n",
    "Visualize training and validation loss to detect overfitting or underfitting during training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ==================== Confusion Matrix ====================\n",
    "val_probs = np.array(val_probs)\n",
    "val_preds = (val_probs >= 0.5).astype(int)\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix on Validation Set')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Confusion Matrix\n",
    "\n",
    "Visualize how well the classifier distinguishes between the classes using the confusion matrix.\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11783285,
     "sourceId": 98732,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
