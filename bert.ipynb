{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-08T08:39:44.313469Z",
     "iopub.status.busy": "2025-06-08T08:39:44.313279Z",
     "iopub.status.idle": "2025-06-08T08:39:56.658180Z",
     "shell.execute_reply": "2025-06-08T08:39:56.657414Z",
     "shell.execute_reply.started": "2025-06-08T08:39:44.313431Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import AutoTokenizer, AutoModel, AutoConfig\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import emoji\n",
    "!pip install contractions\n",
    "import contractions\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* PyTorch: Core library for building and training neural networks.\n",
    "\n",
    "* Transformers: Provides pre-trained models and tokenizers from Hugging Face.\n",
    "\n",
    "* scikit-learn: Offers utilities for evaluation metrics and handling class imbalance.\n",
    "\n",
    "* pandas: Facilitates data manipulation and analysis.\n",
    "\n",
    "* tqdm: Displays progress bars for loops.\n",
    "\n",
    "* re & emoji: Used for text preprocessing tasks.\n",
    "\n",
    "* contractions: Expands English contractions (e.g., \"can't\" to \"cannot\").\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Set the device to GPU if available, otherwise CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "#Specify the pretrained model name (can be changed to any Hugging Face model)\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "#Load the tokenizer corresponding to the chosen pretrained model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* Device Setup: Utilizes GPU if available; otherwise, defaults to CPU.\n",
    "\n",
    "* Tokenizer: Loads the BERT tokenizer to convert text into tokens suitable for the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Custom Dataset class for sentiment analysis data\n",
    "class SentimentDataset(Dataset):\n",
    "    def __init__(self, texts, labels=None, tokenizer=None, max_len=128):\n",
    "        self.texts = texts              #List of raw text samples\n",
    "        self.labels = labels            #Optional list of labels\n",
    "        self.tokenizer = tokenizer      #Tokenizer to encode the texts\n",
    "        self.max_len = max_len          #Maximum sequence length for padding/truncation\n",
    "\n",
    "    def __len__(self):\n",
    "        #returns the number of samples\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #Tokenize and encode the text at the given index\n",
    "        encoding = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            padding='max_length',       #Pad to max_len\n",
    "            truncation=True,            #Truncate if longer than max_len\n",
    "            max_length=self.max_len,\n",
    "            return_tensors='pt'         #Return PyTorch tensors\n",
    "        )\n",
    "\n",
    "        #Prepare the dictionary of inputs for the model, squeezing batch dimension\n",
    "        item = {\n",
    "            'input_ids': encoding['input_ids'].squeeze(0),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(0),\n",
    "        }\n",
    "\n",
    "        #Add label tensor if labels are provided\n",
    "        if self.labels is not None:\n",
    "            item['Label'] = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "        return item\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* SentimentDataset: Custom dataset class that:\n",
    "\n",
    "* Cleans and tokenizes text data.\n",
    "\n",
    "* Prepares inputs for the BERT model.\n",
    "\n",
    "* Handles optional labels for supervised learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-3/train_dataset.csv\")\n",
    "val_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-3/val_dataset.csv\")\n",
    "test_df = pd.read_csv(\"/kaggle/input/ai-2-dl-for-nlp-2025-homework-3/test_dataset.csv\")\n",
    "\n",
    "train_df[\"raw_text\"] = train_df[\"Text\"]\n",
    "train_df[\"label\"] = train_df[\"Label\"]\n",
    "\n",
    "val_df[\"raw_text\"] = val_df[\"Text\"]\n",
    "val_df[\"label\"] = val_df[\"Label\"]\n",
    "\n",
    "test_df[\"raw_text\"] = test_df[\"Text\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* Data Loading: Reads training, validation, and test datasets.\n",
    "\n",
    "* Preprocessing: Applies text cleaning to each dataset and adds relevant columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Extract labels as NumPy arrays (not used directly here, but often for metrics or analysis)\n",
    "y_train = train_df[\"label\"].values\n",
    "y_val = val_df[\"label\"].values\n",
    "\n",
    "#Create dataset objects for training, validation, and test sets using the SentimentDataset class\n",
    "train_dataset = SentimentDataset(\n",
    "    texts=train_df[\"Text\"].tolist(),    #List of training texts\n",
    "    labels=train_df[\"Label\"].tolist(),  #Corresponding training labels\n",
    "    tokenizer=tokenizer                  #Tokenizer for encoding\n",
    ")\n",
    "\n",
    "val_dataset = SentimentDataset(\n",
    "    texts=val_df[\"Text\"].tolist(),      #list of validation texts\n",
    "    labels=val_df[\"Label\"].tolist(),    #Corresponding validation labels\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "test_dataset = SentimentDataset(\n",
    "    texts=test_df[\"Text\"].tolist(),     #Test texts (labels not provided)\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "#Create DataLoaders to efficiently batch and optionally shuffle data during training/evaluation\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)  # Shuffle for training\n",
    "val_loader = DataLoader(val_dataset, batch_size=64)                    # No shuffle for validation\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)                  # No shuffle for test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* Datasets: Creates instances of the custom dataset for training, validation, and testing.\n",
    "\n",
    "* DataLoaders: Facilitates batch processing and shuffling for model training and evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Custom binary classifier using a pretrained BERT model as the base\n",
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, base_model):\n",
    "        super().__init__()\n",
    "        self.bert = base_model                     #Pretrained BERT model\n",
    "        self.dropout = nn.Dropout(0.4162992069057314)          #Dropout layer for regularization\n",
    "        #linear layer to map BERT's hidden state to 2 output classes (binary classification)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        #Forward pass through BERT model\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #Extract [CLS] token representation from last hidden state (batch_size, hidden_size)\n",
    "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
    "        x = self.dropout(cls_output)                #Apply dropout\n",
    "        return self.classifier(x)                   #Get logits for 2 classes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* BertBinaryClassifier: Custom model that:\n",
    "\n",
    "* Utilizes a pre-trained BERT model.\n",
    "\n",
    "1. Applies dropout for regularization.\n",
    "\n",
    "1. Adds a linear layer for binary classification based on the [CLS] token representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "base_model = AutoModel.from_pretrained(model_name, config=config)\n",
    "model = BertBinaryClassifier(base_model).to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* Model Setup: Loads the pre-trained BERT model and initializes the custom classifier, moving it to the appropriate device (GPU or CPU)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#Compute balanced class weights to handle class imbalance in training data\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight=\"balanced\",\n",
    "    classes=[0, 1],                #Classes for binary classification\n",
    "    y=train_df[\"Label\"]           # abels from training data\n",
    ")\n",
    "\n",
    "#Convert class weights to a PyTorch tensor and move to the current device (CPU or GPU)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "#Define the loss function with class weights to penalize underrepresented classes more\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "#Set up the AdamW optimizer with a specified learning rate\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1.2298191651702114e-05)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* Class Weights: Computes weights to handle class imbalance in the dataset.\n",
    "\n",
    "* Loss Function: Uses weighted cross-entropy loss for classification.\n",
    "\n",
    "* Optimizer: Employs AdamW optimizer with a specified learning rate for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    model.train()  #Set model to training mode\n",
    "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}\")\n",
    "    for batch in loop:\n",
    "        #Move inputs and labels to device\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"Label\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()             #Clear gradients\n",
    "        outputs = model(input_ids, attention_mask)  #Forward pass\n",
    "        loss = criterion(outputs, labels)             #Compute loss\n",
    "        loss.backward()                  #Backpropagation\n",
    "        optimizer.step()                 #Update parameters\n",
    "\n",
    "        loop.set_postfix(loss=loss.item())  #Show current loss\n",
    "\n",
    "    model.eval()  #Set model to evaluation mode\n",
    "    preds, true_labels = [], []\n",
    "    val_targets = []\n",
    "    val_probs = []\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"Label\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask)\n",
    "            pred = torch.argmax(outputs, dim=1)  #Get predicted classes\n",
    "\n",
    "            preds.extend(pred.cpu().numpy())\n",
    "            true_labels.extend(labels.cpu().numpy())\n",
    "            #Apply softmax to convert logits to probabilities\n",
    "            probs = F.softmax(outputs, dim=1)[:, 1] # Get probability of the positive class (class 1)\n",
    "    \n",
    "            #Extend lists with the current batch's data\n",
    "            val_targets.extend(labels.cpu().numpy())\n",
    "            val_probs.extend(probs.cpu().numpy())\n",
    "\n",
    "    acc = accuracy_score(true_labels, preds)\n",
    "    print(f\"\\nValidation Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(true_labels, preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation:\n",
    "\n",
    "* Training Loop: Iterates over epochs, performing forward and backward passes, and updates model parameters.\n",
    "\n",
    "* Evaluation: After each epoch, evaluates the model on the validation set and prints accuracy and classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# === Generate Submission ===\n",
    "model.eval()\n",
    "# --- Setup for submission and t-SNE ---\n",
    "submission_preds = []\n",
    "bert_embeddings_list = []\n",
    "bert_pred_labels_list = []\n",
    "NUM_SAMPLES_FOR_TSNE = 2000 # Limit samples for faster plotting\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Predicting and Generating Embeddings\"):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "\n",
    "        # --- Part 1: Get predictions (for submission) ---\n",
    "        # Call the full model to get the final logits\n",
    "        logits = model(input_ids, attention_mask)\n",
    "        predictions = torch.argmax(logits, dim=1)\n",
    "        submission_preds.extend(predictions.cpu().numpy())\n",
    "\n",
    "        # --- Part 2: Get embeddings (for t-SNE) ---\n",
    "        # To get embeddings, call the internal .bert module directly.\n",
    "        # This returns the object that has the .last_hidden_state attribute.\n",
    "        if len(bert_pred_labels_list) < NUM_SAMPLES_FOR_TSNE:\n",
    "            bert_output = model.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            cls_embeddings = bert_output.last_hidden_state[:, 0, :] # Extract [CLS] token\n",
    "            \n",
    "            bert_embeddings_list.append(cls_embeddings.cpu())\n",
    "            bert_pred_labels_list.extend(predictions.cpu().numpy()) # Use predicted labels for color\n",
    "\n",
    "# --- Create Submission File ---\n",
    "test_df[\"Label\"] = submission_preds\n",
    "test_df[[\"ID\", \"Label\"]].to_csv(\"submission.csv\", index=False)\n",
    "print(\"âœ… Submission saved using BERT\")\n",
    "\n",
    "# --- Prepare data for t-SNE plot ---\n",
    "bert_embeddings = torch.cat(bert_embeddings_list, dim=0).numpy()\n",
    "bert_labels = np.array(bert_pred_labels_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ“¦ Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "import emoji\n",
    "from collections import Counter\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, classification_report, roc_curve, auc, confusion_matrix\n",
    ")\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸŒ¥ï¸ Generate Word Cloud\n",
    "def plot_wordcloud(text_series, filename):\n",
    "    text = ' '.join(text_series.dropna().astype(str))\n",
    "    wc = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wc, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, bbox_inches='tight')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ“ Compare token counts before and after cleaning\n",
    "def plot_length_distribution(raw_texts, clean_texts, filename='text_len_dist.png'):\n",
    "    raw_lengths = raw_texts.dropna().astype(str).str.split().apply(len)\n",
    "    clean_lengths = clean_texts.dropna().astype(str).str.split().apply(len)\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(raw_lengths, bins=50, alpha=0.6, label='Raw', color='red')\n",
    "    plt.hist(clean_lengths, bins=50, alpha=0.6, label='Clean', color='green')\n",
    "    plt.xlabel(\"Text Length (Tokens)\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Text Length Distribution: Raw vs Clean\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ˜‚ Extract emojis from a string\n",
    "def extract_emojis(text):\n",
    "    return [char for char in text if char in emoji.EMOJI_DATA]\n",
    "\n",
    "# ðŸ“Š Plot most common emojis\n",
    "def plot_emoji_freq(texts, top_n=10, filename='emoji_freq.png'):\n",
    "    all_emojis = []\n",
    "    for text in texts.dropna().astype(str):\n",
    "        all_emojis.extend(extract_emojis(text))\n",
    "\n",
    "    top_emojis = Counter(all_emojis).most_common(top_n)\n",
    "    if not top_emojis:\n",
    "        print(\"No emojis found.\")\n",
    "        return\n",
    "\n",
    "    labels, values = zip(*top_emojis)\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(labels, values, color='orange')\n",
    "    plt.title(\"Top Emojis Before Conversion\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ§­ Visualize sentiment polarity from TextBlob\n",
    "def plot_sentiment_distribution(texts, filename='sent_pol.png'):\n",
    "    texts = texts.dropna().astype(str)\n",
    "    polarities = [TextBlob(text).sentiment.polarity for text in texts]\n",
    "\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.hist(polarities, bins=50, color='blue', alpha=0.7)\n",
    "    plt.xlabel(\"Sentiment Polarity\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.title(\"Sentiment Polarity Distribution (TextBlob)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ§® Visualize class balance in train/val sets\n",
    "def plot_class_distribution(y_train, y_val, filename='train+val_dist.png'):\n",
    "    labels = ['Train 0', 'Train 1', 'Val 0', 'Val 1']\n",
    "    values = [\n",
    "        (y_train == 0).sum(), (y_train == 1).sum(),\n",
    "        (y_val == 0).sum(), (y_val == 1).sum()\n",
    "    ]\n",
    "\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.bar(labels, values, color=['red', 'blue', 'red', 'blue'])\n",
    "    plt.title(\"Class Distribution in Train and Validation Sets\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename)\n",
    "    plt.show()\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# âœ… Run all plots (ensure your data is defined: train_df, clean_text, y_train, y_val, etc.)\n",
    "plot_wordcloud(train_df['Text'], 'raw_wc.png')\n",
    "\n",
    "plot_emoji_freq(train_df['raw_text'])\n",
    "plot_class_distribution(y_train, y_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ“ˆ Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(val_targets, val_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f\"ROC Curve (AUC = {roc_auc:.4f})\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', color='gray')\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"Validation ROC Curve\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ” t-SNE Plot of BERT Embeddings\n",
    "tsne = TSNE(n_components=2, perplexity=30, learning_rate=200, n_iter=1000, random_state=42)\n",
    "bert_tsne_embeds = tsne.fit_transform(bert_embeddings)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "colors = ['red' if l == 0 else 'green' for l in bert_labels]\n",
    "plt.scatter(bert_tsne_embeds[:, 0], bert_tsne_embeds[:, 1], c=colors, alpha=0.6)\n",
    "plt.title(\"t-SNE Visualization of BERT [CLS] Embeddings\")\n",
    "plt.xlabel(\"t-SNE Dim 1\")\n",
    "plt.ylabel(\"t-SNE Dim 2\")\n",
    "plt.legend(handles=[\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='Negative', markerfacecolor='red', markersize=8),\n",
    "    plt.Line2D([0], [0], marker='o', color='w', label='Positive', markerfacecolor='green', markersize=8)\n",
    "])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ðŸ“‰ Confusion Matrix\n",
    "val_probs = np.array(val_probs)\n",
    "val_preds = (val_probs >= 0.5).astype(int)\n",
    "cm = confusion_matrix(val_targets, val_preds)\n",
    "labels = ['Negative', 'Positive']\n",
    "\n",
    "plt.figure(figsize=(6, 5))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix on Validation Set')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 11781620,
     "sourceId": 98723,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 31011,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
